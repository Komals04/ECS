import boto3
import csv
from datetime import datetime, timedelta
import time

def write_to_csv(filename, headers, rows):
    with open(filename, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(headers)
        writer.writerows(rows)

def call_with_retries(func, max_retries=5):
    for attempt in range(1, max_retries + 1):
        try:
            return func()
        except Exception as e:
            print(f"Attempt {attempt} failed: {e}")
            if attempt == max_retries:
                raise
            else:
                wait_time = (2 ** attempt) * 0.5  # Exponential backoff with jitter
                print(f"Retrying in {wait_time} seconds...")
                time.sleep(wait_time)

def get_ecs_clusters():
    ecs_client = boto3.client('ecs')
    clusters = ecs_client.list_clusters()['clusterArns']
    return clusters

def get_load_balancers(cluster_arn):
    def _get_load_balancers_inner():
        ecs_client = boto3.client('ecs')
        services = ecs_client.list_services(cluster=cluster_arn)['serviceArns']
        elbv2_client = boto3.client('elbv2')
        load_balancers = []

        for service_arn in services:
            response = ecs_client.describe_services(cluster=cluster_arn, services=[service_arn])
            service = response['services'][0]
            for lb in service.get('loadBalancers', []):
                if 'targetGroupArn' in lb:  # Check if targetGroupArn exists
                    load_balancers.append(lb['targetGroupArn'])
        return load_balancers

    return call_with_retries(_get_load_balancers_inner)

def get_metrics(target_group_arn, start_time, end_time):
    cloudwatch_client = boto3.client('cloudwatch')
    response = cloudwatch_client.get_metric_statistics(
        Namespace='AWS/ApplicationELB',
        MetricName='Per AppELB, Per AZ, Per TG Metrics',
        Dimensions=[
            {'Name': 'TargetGroup', 'Value': target_group_arn},
            {'Name': 'MetricName', 'Value': 'Total number of connections'}
        ],
        StartTime=start_time,
        EndTime=end_time,
        Period=3600,  # 1 hour
        Statistics=['Sum']
    )
    datapoints = response.get('Datapoints', [])
    total_connections = sum(datapoint['Sum'] for datapoint in datapoints)
    return total_connections

def main():
    regions = ['us-east-1', 'us-east-2', 'us-west-2']

    # Prepare data for CSV
    headers = ['Region', 'ECS Cluster Name', 'Target Group', 'Total Connections in 1hr']
    rows = []

    for region in regions:
        print(f"Processing region {region}...")
        boto3.setup_default_session(region_name=region)
        clusters = get_ecs_clusters()

        for cluster_arn in clusters:
            cluster_name = cluster_arn.split('/')[-1]
            print(f"Retrieving load balancers for ECS cluster {cluster_name} in region {region}...")
            target_groups = get_load_balancers(cluster_arn)
            print(f"Found {len(target_groups)} target groups for ECS cluster {cluster_name}")

            for target_group_arn in target_groups:
                total_connections = get_metrics(target_group_arn, datetime.utcnow() - timedelta(hours=1), datetime.utcnow())
                rows.append([region, cluster_name, target_group_arn, total_connections])

    filename = 'ecs_load_balancer_metrics.csv'
    write_to_csv(filename, headers, rows)

    print(f'Data saved to {filename}')

if __name__ == "__main__":
    main()
