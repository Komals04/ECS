import boto3
import csv
from datetime import datetime, timedelta

def list_ecs_clusters():
    client = boto3.client('ecs')
    response = client.list_clusters()
    return response['clusterArns']

def list_target_groups(load_balancer_arn):
    client = boto3.client('elbv2')
    response = client.describe_target_groups(LoadBalancerArn=load_balancer_arn)
    return [tg['TargetGroupName'] for tg in response['TargetGroups']]

def get_load_balancer_arn(cluster_arn):
    client = boto3.client('ecs')
    response = client.describe_clusters(clusters=[cluster_arn])
    cluster = response['clusters'][0]
    return cluster.get('defaultCapacityProviderStrategy', {}).get('capacityProvider')

def get_cloudwatch_metrics(cluster_arn, target_group, start_time, end_time):
    client = boto3.client('cloudwatch')

    metrics = [
        {
            'Namespace': 'AWS/ECS',
            'MetricName': 'RequestCount',
            'Dimensions': [
                {
                    'Name': 'ClusterName',
                    'Value': cluster_arn
                }
            ],
            'Statistic': 'Sum',
            'Unit': 'Count'
        },
        {
            'Namespace': 'AWS/ApplicationELB',
            'MetricName': 'RequestCountPerTarget',
            'Dimensions': [
                {
                    'Name': 'TargetGroup',
                    'Value': target_group
                }
            ],
            'Statistic': 'Sum',
            'Unit': 'Count'
        },
        {
            'Namespace': 'AWS/ApplicationELB',
            'MetricName': 'TargetResponseTime',
            'Dimensions': [
                {
                    'Name': 'TargetGroup',
                    'Value': target_group
                }
            ],
            'Statistic': 'Average',
            'Unit': 'Seconds'
        }
    ]

    data = []
    for metric in metrics:
        response = client.get_metric_statistics(
            Namespace=metric['Namespace'],
            MetricName=metric['MetricName'],
            Dimensions=metric['Dimensions'],
            StartTime=start_time,
            EndTime=end_time,
            Period=3600,
            Statistics=[metric['Statistic']]
        )
        for datapoint in response['Datapoints']:
            data.append({
                'ClusterName': cluster_arn,
                'TargetGroup': target_group,
                'MetricName': metric['MetricName'],
                'Timestamp': datapoint['Timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                'Value': datapoint[metric['Statistic']]
            })
    return data

def save_to_csv(data, filename):
    with open(filename, 'w', newline='') as csvfile:
        fieldnames = ['ClusterName', 'TargetGroup', 'MetricName', 'Timestamp', 'Value']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for row in data:
            writer.writerow(row)

def main():
    clusters = list_ecs_clusters()
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=1)

    all_metrics_data = []
    for cluster_arn in clusters:
        lb_arn = get_load_balancer_arn(cluster_arn)
        target_groups = list_target_groups(lb_arn)
        for target_group in target_groups:
            metrics_data = get_cloudwatch_metrics(cluster_arn, target_group, start_time, end_time)
            all_metrics_data.extend(metrics_data)

    filename = 'ecs_clusters_metrics.csv'
    save_to_csv(all_metrics_data, filename)
    print(f"Metrics data saved to {filename}")

if __name__ == "__main__":
    main()
