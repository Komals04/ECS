import boto3
import csv
from datetime import datetime, timedelta
import time

def write_to_csv(filename, data):
    with open(filename, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Load Balancer ARN', 'Response Time (ms)'])
        for lb_arn, response_time in data.items():
            writer.writerow([lb_arn, response_time])

def call_with_retries(func, max_retries=5):
    for attempt in range(1, max_retries + 1):
        try:
            return func()
        except Exception as e:
            print(f"Attempt {attempt} failed: {e}")
            if attempt == max_retries:
                raise
            else:
                wait_time = (2 ** attempt) * 0.5  # Exponential backoff with jitter
                print(f"Retrying in {wait_time} seconds...")
                time.sleep(wait_time)

def get_ecs_clusters(region):
    ecs_client = boto3.client('ecs', region_name=region)
    clusters = ecs_client.list_clusters()['clusterArns']
    return clusters

def get_load_balancers(region):
    def _get_load_balancers_inner():
        ecs_client = boto3.client('ecs', region_name=region)
        clusters = get_ecs_clusters(region)
        load_balancers = []
        for cluster_arn in clusters:
            services = ecs_client.list_services(cluster=cluster_arn)['serviceArns']
            for service_arn in services:
                response = ecs_client.describe_services(cluster=cluster_arn, services=[service_arn])
                service = response['services'][0]
                for lb in service.get('loadBalancers', []):
                    if 'targetGroupArn' in lb:  # Check if targetGroupArn exists
                        load_balancers.append(lb['targetGroupArn'])
        return load_balancers

    return call_with_retries(_get_load_balancers_inner)

def get_target_response_time(load_balancer_arn, start_time, end_time, region):
    cloudwatch_client = boto3.client('cloudwatch', region_name=region)
    response = cloudwatch_client.get_metric_statistics(
        Namespace='AWS/ApplicationELB',
        MetricName='TargetResponseTime',
        Dimensions=[
            {'Name': 'LoadBalancer', 'Value': load_balancer_arn},
        ],
        StartTime=start_time,
        EndTime=end_time,
        Period=3600,  # 1 hour
        Statistics=['Average']
    )
    datapoints = response.get('Datapoints', [])
    if datapoints:
        return datapoints[0]['Average']
    else:
        return 0

def main():
    regions = ['us-east-1', 'us-east-2', 'us-west-2']
    start_time = datetime.utcnow() - timedelta(hours=3)
    end_time = datetime.utcnow()

    all_load_balancers = {}
    for region in regions:
        load_balancers = get_load_balancers(region)
        for lb_arn in load_balancers:
            response_time = get_target_response_time(lb_arn, start_time, end_time, region)
            all_load_balancers[lb_arn] = response_time

    filename = 'load_balancer_response_times.csv'
    write_to_csv(filename, all_load_balancers)
    print(f'Data saved to {filename}')

if __name__ == "__main__":
    main()
